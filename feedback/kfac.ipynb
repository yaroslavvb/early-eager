{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFAC for autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers + common utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MKL\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "import time\n",
    "\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "\n",
    "USE_MKL = True\n",
    "\n",
    "\n",
    "if USE_MKL:\n",
    "  assert np.__config__.get_info(\"lapack_mkl_info\"), \"No MKL detected :(\"\n",
    "  print(\"Using MKL\")\n",
    "\n",
    "# for line profiling\n",
    "try:\n",
    "    profile  # throws an exception when profile isn't defined\n",
    "except NameError:\n",
    "    profile = lambda x: x   # if it's not defined simply ignore the decorator.\n",
    "    \n",
    "\n",
    "# helper utilities\n",
    "def W_uniform(s1, s2): # uniform weight init from Ng UFLDL\n",
    "  r = np.sqrt(6) / np.sqrt(s1 + s2 + 1)\n",
    "  result = np.random.random(2*s2*s1)*2*r-r\n",
    "  return result.astype(dtype)\n",
    "\n",
    "def load_MNIST_images(filename):\n",
    "  \"\"\"\n",
    "  returns a 28x28x[number of MNIST images] matrix containing\n",
    "  the raw MNIST images\n",
    "  :param filename: input data file\n",
    "  \"\"\"\n",
    "  with open(filename, \"r\") as f:\n",
    "    magic = np.fromfile(f, dtype=np.dtype('>i4'), count=1)\n",
    "\n",
    "    num_images = int(np.fromfile(f, dtype=np.dtype('>i4'), count=1))\n",
    "    num_rows = int(np.fromfile(f, dtype=np.dtype('>i4'), count=1))\n",
    "    num_cols = int(np.fromfile(f, dtype=np.dtype('>i4'), count=1))\n",
    "\n",
    "    images = np.fromfile(f, dtype=np.ubyte)\n",
    "    images = images.reshape((num_images, num_rows * num_cols)).transpose()\n",
    "    images = images.astype(np.float64) / 255\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return images\n",
    "\n",
    "def _read32(bytestream):\n",
    "  dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "  return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "def extract_images(f):\n",
    "  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\n",
    "  Args:\n",
    "    f: A file object that can be passed into a gzip reader.\n",
    "  Returns:\n",
    "    data: A 4D uint8 numpy array [index, y, x, depth].\n",
    "  Raises:\n",
    "    ValueError: If the bytestream does not start with 2051.\n",
    "  \"\"\"\n",
    "  print('Extracting', f.name)\n",
    "  with gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2051:\n",
    "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
    "                       (magic, f.name))\n",
    "    num_images = _read32(bytestream)\n",
    "    rows = _read32(bytestream)\n",
    "    cols = _read32(bytestream)\n",
    "    buf = bytestream.read(rows * cols * num_images)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    data = data.reshape(num_images, rows, cols, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def t(x):\n",
    "  return tf.transpose(x)\n",
    "\n",
    "# TensorShape([Dimension(2), Dimension(10)]) => (2, 10)\n",
    "def fix_shape(tf_shape):\n",
    "  return tuple(int(dim) for dim in tf_shape)\n",
    "\n",
    "def partition_list(l, sizes):\n",
    "  \"\"\"Partition l into sublists of given sizes.\"\"\"\n",
    "  assert len(l.shape) == 1\n",
    "  assert np.sum(sizes) == l.shape[0]\n",
    "  splits = []\n",
    "  current_idx = 0\n",
    "  for i in range(len(sizes)):\n",
    "    splits.append(l[current_idx: current_idx+sizes[i]])\n",
    "    current_idx += sizes[i]\n",
    "  return splits\n",
    "\n",
    "def unflatten(Wf, fs):\n",
    "  \"\"\"Turn flattened Tensor into list of rank-2 tensors with given sizes.\"\"\"\n",
    "  \n",
    "  Wf_shape = fix_shape(Wf.shape)\n",
    "  if len(Wf_shape)==2 and Wf_shape[1] == 1:  # treat col mats as vectors\n",
    "    Wf = tf.reshape(Wf, [-1])\n",
    "  dims = [(fs[i+1],fs[i]) for i in range(len(fs)-1)]\n",
    "  sizes = [s[0]*s[1] for s in dims]\n",
    "  assert len(Wf.shape) == 1\n",
    "  assert np.sum(sizes)==Wf.shape[0]\n",
    "  Wsf = partition_list(Wf, sizes)\n",
    "  Ws = [unvec(Wsf[i], dims[i][0]) for i in range(len(sizes))]\n",
    "  return Ws\n",
    "\n",
    "def unvec(vec, rows):\n",
    "  \"\"\"Turn vectorized version of tensor into original matrix with given\n",
    "  number of rows.\"\"\"\n",
    "  assert len(vec.shape) == 1\n",
    "  assert vec.shape[0]%rows == 0\n",
    "  cols = int(vec.shape[0]//rows)\n",
    "  return tf.transpose(tf.reshape(vec, (cols, -1)))\n",
    "\n",
    "\n",
    "def vec(mat):\n",
    "  \"\"\"Vectorize matrix.\"\"\"\n",
    "  return tf.reshape(tf.transpose(mat), [-1,1])\n",
    "\n",
    "\n",
    "def flatten(Ws):\n",
    "  \"\"\"Inverse of unflatten.\"\"\"\n",
    "  return tf.concat([tf.reshape(vec(W),(-1,)) for W in Ws], axis=0)\n",
    "\n",
    "def L2(t):\n",
    "  return tf.reduce_sum(tf.square(t))\n",
    "\n",
    "def Identity(n):\n",
    "  \"\"\"Identity matrix of size n.\"\"\"\n",
    "  return tf.diag(tf.ones((n,), dtype=dtype))\n",
    "\n",
    "def regularized_inverse(mat, lambda_):\n",
    "  n = int(mat.shape[0])\n",
    "  assert n == int(mat.shape[1])\n",
    "  regmat = mat + lambda_*Identity(n)\n",
    "  if USE_MKL:   # MKL is 5x faster than TF for inverses\n",
    "    return tf.constant(scipy.linalg.inv(regmat.numpy()))\n",
    "  return tf.linalg.inv(regmat)\n",
    "\n",
    "# Time tracking functions\n",
    "global_time_list = []\n",
    "global_last_time = 0\n",
    "def record_time():\n",
    "  global global_last_time, global_time_list\n",
    "  new_time = time.perf_counter()\n",
    "  global_time_list.append(new_time - global_last_time)\n",
    "  global_last_time = time.perf_counter()\n",
    "\n",
    "def summarize_time(time_list=None):\n",
    "  if time_list is None:\n",
    "    time_list = global_time_list\n",
    "\n",
    "  if time_list[0]>3600*10:   # large first interval means no relative ts\n",
    "    del time_list[0]\n",
    "    \n",
    "  time_list = 1000*np.array(time_list)  # get seconds, convert to ms\n",
    "  if len(time_list)>0:\n",
    "    min = np.min(time_list)\n",
    "    median = np.median(time_list)\n",
    "    formatted = [\"%.2f\"%(d,) for d in time_list[:10]]\n",
    "    print(\"Times: min: %.2f, median: %.2f, mean: %.2f\"%(min, median, np.mean(time_list)))\n",
    "    #    print(\"Times: min: %.2f, median: %.2f, mean: %.2f\"%(min, median,\",\".join(formatted)))\n",
    "  else:\n",
    "    print(\"Times: <empty>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement KFAC gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_and_grad(Wf):\n",
    "  \"\"\"Returns cost, gradient for current parameter vector.\"\"\"\n",
    "  \n",
    "  W = unflatten(Wf, fs[1:])   # perftodo: this creates transposes\n",
    "  W.insert(0, X)\n",
    "\n",
    "  A = [None]*(n+2)\n",
    "  A[1] = W[0]\n",
    "  for i in range(1, n+1):\n",
    "    A[i+1] = tf.sigmoid(W[i] @ A[i])\n",
    "  err = (A[3] - A[1])\n",
    "\n",
    "  def d_sigmoid(y):\n",
    "    return y*(1-y)\n",
    "\n",
    "  B = [None]*(n+1)\n",
    "  B2 = [None]*(n+1)\n",
    "  B[n] = err*d_sigmoid(A[n+1])\n",
    "  sampled_labels = tf.random_normal((f(n), f(-1)), dtype=dtype, seed=0)\n",
    "  B2[n] = sampled_labels*d_sigmoid(A[n+1])\n",
    "  for i in range(n-1, -1, -1):\n",
    "    backprop = t(W[i+1]) @ B[i+1]\n",
    "    backprop2 = t(W[i+1]) @ B2[i+1]\n",
    "    B[i] = backprop*d_sigmoid(A[i+1])\n",
    "    B2[i] = backprop2*d_sigmoid(A[i+1])\n",
    "\n",
    "  dW = [None]*(n+1)\n",
    "  pre_dW = [None]*(n+1)  # preconditioned dW\n",
    "\n",
    "  cov_A = [None]*(n+1)    # covariance of activations[i]\n",
    "  cov_B2 = [None]*(n+1)   # covariance of synthetic backprops[i]\n",
    "  vars_svd_A = [None]*(n+1)\n",
    "  vars_svd_B2 = [None]*(n+1)\n",
    "  for i in range(1,n+1):\n",
    "    cov_A[i] = A[i]@t(A[i])/dsize\n",
    "    cov_B2[i] = B2[i]@t(B2[i])/dsize\n",
    "    whitened_A = regularized_inverse(cov_A[i], lambda_) @ A[i]\n",
    "    whitened_B = regularized_inverse(cov_B2[i], lambda_) @ B[i]\n",
    "    pre_dW[i] = (whitened_B @ t(whitened_A))/dsize\n",
    "    dW[i] = (B[i] @ t(A[i]))/dsize\n",
    "\n",
    "  reconstruction = L2(err) / (2 * dsize)\n",
    "  loss = reconstruction\n",
    "\n",
    "  grad = flatten(dW[1:])\n",
    "  kfac_grad = flatten(pre_dW[1:])\n",
    "  return loss, grad, kfac_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data/architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float32\n",
    "TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "source_url = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "local_file = base.maybe_download(TRAIN_IMAGES, '/tmp',\n",
    "                                 source_url + TRAIN_IMAGES)\n",
    "train_images = extract_images(open(local_file, 'rb'))\n",
    "train_images = train_images.reshape(60000, 28**2).T.astype(np.float64)/255\n",
    "dsize = 10000\n",
    "fs = [dsize, 28*28, 196, 28*28]  # layer sizes\n",
    "lambda_=3e-3\n",
    "def f(i): return fs[i+1]  # W[i] has shape f[i] x f[i-1]\n",
    "n = len(fs) - 2\n",
    "X = train_images[:,:dsize].astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(92.8628, shape=(), dtype=float32)\n",
      "tf.Tensor(40.3994, shape=(), dtype=float32)\n",
      "tf.Tensor(30.2901, shape=(), dtype=float32)\n",
      "tf.Tensor(28.4983, shape=(), dtype=float32)\n",
      "tf.Tensor(27.8251, shape=(), dtype=float32)\n",
      "tf.Tensor(27.462, shape=(), dtype=float32)\n",
      "tf.Tensor(27.2289, shape=(), dtype=float32)\n",
      "tf.Tensor(27.0619, shape=(), dtype=float32)\n",
      "tf.Tensor(26.933, shape=(), dtype=float32)\n",
      "tf.Tensor(26.8276, shape=(), dtype=float32)\n",
      "tf.Tensor(26.7376, shape=(), dtype=float32)\n",
      "tf.Tensor(26.658, shape=(), dtype=float32)\n",
      "tf.Tensor(26.5854, shape=(), dtype=float32)\n",
      "tf.Tensor(26.5176, shape=(), dtype=float32)\n",
      "tf.Tensor(26.4531, shape=(), dtype=float32)\n",
      "tf.Tensor(26.3907, shape=(), dtype=float32)\n",
      "tf.Tensor(26.3294, shape=(), dtype=float32)\n",
      "tf.Tensor(26.2686, shape=(), dtype=float32)\n",
      "tf.Tensor(26.2078, shape=(), dtype=float32)\n",
      "tf.Tensor(26.1463, shape=(), dtype=float32)\n",
      "tf.Tensor(26.084, shape=(), dtype=float32)\n",
      "tf.Tensor(26.0204, shape=(), dtype=float32)\n",
      "tf.Tensor(25.9553, shape=(), dtype=float32)\n",
      "tf.Tensor(25.8885, shape=(), dtype=float32)\n",
      "tf.Tensor(25.8197, shape=(), dtype=float32)\n",
      "tf.Tensor(25.749, shape=(), dtype=float32)\n",
      "tf.Tensor(25.6761, shape=(), dtype=float32)\n",
      "tf.Tensor(25.601, shape=(), dtype=float32)\n",
      "tf.Tensor(25.5236, shape=(), dtype=float32)\n",
      "tf.Tensor(25.4439, shape=(), dtype=float32)\n",
      "tf.Tensor(25.362, shape=(), dtype=float32)\n",
      "tf.Tensor(25.2777, shape=(), dtype=float32)\n",
      "tf.Tensor(25.1913, shape=(), dtype=float32)\n",
      "tf.Tensor(25.1027, shape=(), dtype=float32)\n",
      "tf.Tensor(25.012, shape=(), dtype=float32)\n",
      "tf.Tensor(24.9193, shape=(), dtype=float32)\n",
      "tf.Tensor(24.8247, shape=(), dtype=float32)\n",
      "tf.Tensor(24.7284, shape=(), dtype=float32)\n",
      "tf.Tensor(24.6305, shape=(), dtype=float32)\n",
      "tf.Tensor(24.531, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "Wf = tf.constant(W_uniform(fs[2],fs[3]))\n",
    "lr = tf.constant(0.2)\n",
    "\n",
    "losses0 = []\n",
    "for i in range(40):\n",
    "  loss, grad, kfac_grad = loss_and_grad(Wf)\n",
    "  print(loss)\n",
    "  losses0.append(loss.numpy())\n",
    "  Wf-=lr*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using KFAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(92.8628, shape=(), dtype=float32)\n",
      "tf.Tensor(62.0933, shape=(), dtype=float32)\n",
      "tf.Tensor(31.5272, shape=(), dtype=float32)\n",
      "tf.Tensor(17.0098, shape=(), dtype=float32)\n",
      "tf.Tensor(10.1103, shape=(), dtype=float32)\n",
      "tf.Tensor(6.57397, shape=(), dtype=float32)\n",
      "tf.Tensor(4.61933, shape=(), dtype=float32)\n",
      "tf.Tensor(3.47517, shape=(), dtype=float32)\n",
      "tf.Tensor(2.74656, shape=(), dtype=float32)\n",
      "tf.Tensor(2.26078, shape=(), dtype=float32)\n",
      "tf.Tensor(1.91945, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6727, shape=(), dtype=float32)\n",
      "tf.Tensor(1.48772, shape=(), dtype=float32)\n",
      "tf.Tensor(1.34589, shape=(), dtype=float32)\n",
      "tf.Tensor(1.23425, shape=(), dtype=float32)\n",
      "tf.Tensor(1.14428, shape=(), dtype=float32)\n",
      "tf.Tensor(1.07024, shape=(), dtype=float32)\n",
      "tf.Tensor(1.00858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.956685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.912095, shape=(), dtype=float32)\n",
      "tf.Tensor(0.873375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.839401, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80948, shape=(), dtype=float32)\n",
      "tf.Tensor(0.782871, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.737931, shape=(), dtype=float32)\n",
      "tf.Tensor(0.718673, shape=(), dtype=float32)\n",
      "tf.Tensor(0.701119, shape=(), dtype=float32)\n",
      "tf.Tensor(0.685015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.670325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.656784, shape=(), dtype=float32)\n",
      "tf.Tensor(0.644364, shape=(), dtype=float32)\n",
      "tf.Tensor(0.632786, shape=(), dtype=float32)\n",
      "tf.Tensor(0.622213, shape=(), dtype=float32)\n",
      "tf.Tensor(0.612301, shape=(), dtype=float32)\n",
      "tf.Tensor(0.60332, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59475, shape=(), dtype=float32)\n",
      "tf.Tensor(0.587496, shape=(), dtype=float32)\n",
      "tf.Tensor(0.579735, shape=(), dtype=float32)\n",
      "tf.Tensor(0.573927, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "Wf = tf.constant(W_uniform(fs[2],fs[3]))\n",
    "lr = tf.constant(0.2)\n",
    "\n",
    "losses1 = []\n",
    "for i in range(40):\n",
    "  loss, grad, kfac_grad = loss_and_grad(Wf)\n",
    "  print(loss)\n",
    "  losses1.append(loss.numpy())\n",
    "  Wf-=lr*kfac_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYk5JQIRkZj7/129PtmjrdbeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f427409fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(40), losses0, label='gradient')\n",
    "plt.plot(range(40), losses1, label='kfac')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('kfac vs gradient descent')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'numpy.float32' has no attribute 'as_datatype_enum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c25ded2e4e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(t, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mscalar_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sep22/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value, ctx, dtype)\u001b[0m\n\u001b[1;32m    633\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_TensorHandleDataType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mdtype_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_Py_SequenceToTensorHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'numpy.float32' has no attribute 'as_datatype_enum'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "\n",
    "tf.constant(0.1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import resource_variable_ops as rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = rr.ResourceVariable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.read_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.assign_add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4fabd6bb96ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'Tensor'"
     ]
    }
   ],
   "source": [
    "Tensor = torch.cuda.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
